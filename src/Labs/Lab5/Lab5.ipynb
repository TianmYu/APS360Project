{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Maxwell Zheng 1004907871\n",
    "Google Colab: https://colab.research.google.com/drive/1rT7p9Tfa9ciVgkNR2WroAuo6xa26feGg?usp=sharing\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1a\n",
    "\n",
    "# unable to upload to Colab so used local file\n",
    "f = open(r'C:\\Users\\Maxwell\\Documents\\Code\\Python\\APS360\\src\\Labs\\Lab5\\SMSSpamCollection')\n",
    "\n",
    "for line in open(r'C:\\Users\\Maxwell\\Documents\\Code\\Python\\APS360\\src\\Labs\\Lab5\\SMSSpamCollection'):\n",
    "  if 'ham' in line:\n",
    "    print(line)\n",
    "    for line in f:\n",
    "      if 'spam' in line:\n",
    "        print(line)\n",
    "        break\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# spam messages:  747\n",
      "# non-spam messages:  4827\n"
     ]
    }
   ],
   "source": [
    "# 1b\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "with open('SMSSpamCollection') as f:\n",
    "    for line in f:\n",
    "        if 'spam' in line:\n",
    "          i += 1\n",
    "        else:\n",
    "          j += 1\n",
    "        \n",
    "    print(\"# spam messages: \",i)\n",
    "    print(\"# non-spam messages: \",j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c\n",
    "\n",
    "\"\"\"\n",
    "Advatanges:\n",
    "    more accurate\n",
    "    can detect punctation as well as characters\n",
    "Disadvantages:\n",
    "    needs more data\n",
    "    longer processing time\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1d\n",
    "\n",
    "import torchtext\n",
    "\n",
    "text_field = torchtext.data.Field(sequential=True,      \n",
    "                                  tokenize=lambda x: x, \n",
    "                                  include_lengths=True,                                   \n",
    "                                  batch_first=True,\n",
    "                                  use_vocab=True)  \n",
    "\n",
    "label_field = torchtext.data.Field(sequential=False,    \n",
    "                                   use_vocab=False,     \n",
    "                                   is_target=True,      \n",
    "                                   batch_first=True,\n",
    "                                   preprocessing=lambda x: int(x == 'spam')) \n",
    "\n",
    "fields = [('label', label_field), ('sms', text_field)]\n",
    "dataset = torchtext.data.TabularDataset(\"SMSSpamCollection\", \"tsv\", fields)\n",
    "\n",
    "print(dataset[0].sms)\n",
    "print(dataset[0].label)\n",
    "\n",
    "train, valid, test = dataset.split(split_ratio = [0.6,0.2,0.2], stratified=False, strata_field='label', random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e\n",
    "\n",
    "\"\"\"\n",
    "A balanced training set is helpful for training a nerual net because it sees both spam and non-spam\n",
    "and is able to distinguish between the two.\n",
    "It is important to have sample sizes to obtain good accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train_examples = train.examples\n",
    "\n",
    "train_spam = []\n",
    "for item in train.examples:\n",
    "    if item.label == 1:\n",
    "        train_spam.append(item)\n",
    "\n",
    "train.examples = old_train_examples + train_spam * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1f\n",
    "\n",
    "\"\"\"\n",
    "vocab.stoi maps token strs to numerical ids\n",
    "vocab.itos is a list of token strs index by their numerical id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " ' ',\n",
       " 'e',\n",
       " 'o',\n",
       " 't',\n",
       " 'a',\n",
       " 'n',\n",
       " 'i',\n",
       " 's',\n",
       " 'r',\n",
       " 'l',\n",
       " 'h',\n",
       " '.',\n",
       " 'u',\n",
       " 'd',\n",
       " 'y',\n",
       " 'm',\n",
       " 'g',\n",
       " 'c',\n",
       " 'w',\n",
       " 'p',\n",
       " 'f',\n",
       " 'b',\n",
       " 'k',\n",
       " 'I',\n",
       " 'v',\n",
       " '0',\n",
       " 'T',\n",
       " ',',\n",
       " 'S',\n",
       " \"'\",\n",
       " 'O',\n",
       " '1',\n",
       " 'A',\n",
       " 'E',\n",
       " '?',\n",
       " 'N',\n",
       " '2',\n",
       " 'H',\n",
       " '!',\n",
       " 'W',\n",
       " 'C',\n",
       " '8',\n",
       " '5',\n",
       " 'x',\n",
       " 'U',\n",
       " 'Y',\n",
       " 'D',\n",
       " 'R',\n",
       " 'M',\n",
       " '4',\n",
       " '&',\n",
       " 'G',\n",
       " 'L',\n",
       " 'P',\n",
       " 'B',\n",
       " '7',\n",
       " ';',\n",
       " '6',\n",
       " '3',\n",
       " ':',\n",
       " 'j',\n",
       " '9',\n",
       " '-',\n",
       " 'F',\n",
       " 'z',\n",
       " ')',\n",
       " '*',\n",
       " 'K',\n",
       " '/',\n",
       " '#',\n",
       " 'V',\n",
       " 'J',\n",
       " '£',\n",
       " 'X',\n",
       " '\"',\n",
       " 'q',\n",
       " '+',\n",
       " 'ü',\n",
       " '(',\n",
       " 'Q',\n",
       " 'Ü',\n",
       " '=',\n",
       " '@',\n",
       " '‘',\n",
       " '\\x92',\n",
       " '$',\n",
       " '>',\n",
       " '…',\n",
       " '%',\n",
       " '<',\n",
       " 'Z',\n",
       " '\\x94',\n",
       " '|',\n",
       " '~',\n",
       " '\\x93',\n",
       " '»']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.build_vocab(train)\n",
    "text_field.build_vocab(valid)\n",
    "label_field.build_vocab(train)\n",
    "label_field.build_vocab(valid)\n",
    "text_field.vocab.stoi\n",
    "text_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1g\n",
    "\n",
    "\"\"\"\n",
    "unk and pad represent sepcial tokens that will be prepended to the vocab \n",
    "unk: out of vocab works that are unknown\n",
    "pad: padding\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1h\n",
    "\n",
    "trainIter = torchtext.data.BucketIterator(train,batch_size=32,sort_key=lambda x: len(x.sms), sort_within_batch=True, repeat=False)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The max length of input is 61\n",
    "To obtain the number of pad tokens we count the occurence of 1s in the first tensor\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "(tensor([[37,  4,  5,  ...,  7, 36,  2],\n",
      "        [39,  3,  2,  ...,  6, 10, 36],\n",
      "        [55, 49, 25,  ..., 70, 27, 51],\n",
      "        ...,\n",
      "        [55, 11,  3,  ...,  3, 40,  1],\n",
      "        [46,  2, 12,  ..., 27, 33,  1],\n",
      "        [55, 11,  3,  ...,  3, 40,  1]]), tensor([148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,\n",
      "        148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148,\n",
      "        148, 147, 147, 147]))\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1])\n",
      "32\n",
      "(tensor([[41, 32, 28,  2, 46,  2, 46, 55,  2, 38,  2, 73, 36],\n",
      "        [42,  6,  7,  2, 15,  4,  2, 11,  4, 10, 13, 13, 13],\n",
      "        [32, 24, 13, 13, 13,  2, 42,  2, 16,  6, 13, 13, 13],\n",
      "        [38, 70, 38,  2, 33, 51, 59,  5, 22, 33, 44, 27, 21],\n",
      "        [32, 24,  2,  5, 12,  6,  7, 45, 13, 13, 13,  1,  1],\n",
      "        [25, 31, 17,  2, 15,  4,  7,  3, 13, 13, 13,  1,  1],\n",
      "        [28, 12,  3,  7,  2,  8,  2, 23, 14, 16, 13,  1,  1],\n",
      "        [34,  7, 16,  5, 12,  8,  7, 18, 13, 13, 13,  1,  1],\n",
      "        [34,  7, 16,  5,  8, 17,  3, 13, 13, 13,  1,  1,  1],\n",
      "        [32, 24,  2, 19,  6,  7, 13, 13, 13,  1,  1,  1,  1],\n",
      "        [47, 14, 21,  2,  4, 24, 13, 13, 13,  1,  1,  1,  1],\n",
      "        [47, 14, 21,  2,  4, 24, 13, 13, 13,  1,  1,  1,  1],\n",
      "        [46,  2,  5,  4,  4, 13, 13, 13,  1,  1,  1,  1,  1],\n",
      "        [28, 12,  6,  7, 24,  2, 14, 40,  1,  1,  1,  1,  1],\n",
      "        [32, 24,  8,  3, 13, 13, 13,  1,  1,  1,  1,  1,  1],\n",
      "        [37,  8,  5,  3, 13, 13, 13,  1,  1,  1,  1,  1,  1],\n",
      "        [39,  6, 26,  3,  7,  5, 13,  1,  1,  1,  1,  1,  1],\n",
      "        [34, 54, 49, 25, 28, 35,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [47, 14, 21, 13, 13, 13,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24, 13, 13, 13,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24, 13, 13, 13,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24, 13, 13, 13,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [53, 13, 41, 13, 49,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [46,  2, 38, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24,  8,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24,  8,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24, 13,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [47, 14, 21,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [61, 67,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
      "        [32, 24,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]]), tensor([13, 13, 13, 13, 11, 11, 11, 11, 10,  9,  9,  9,  8,  8,  7,  7,  7,  6,\n",
      "         6,  5,  5,  5,  5,  4,  4,  4,  3,  3,  3,  3,  2,  2]))\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "32\n",
      "(tensor([[54,  4,  4,  ...,  9,  9, 13],\n",
      "        [57,  2, 11,  ...,  7, 18, 36],\n",
      "        [49,  3, 26,  ...,  9, 13,  1],\n",
      "        ...,\n",
      "        [37,  4,  2,  ..., 20,  1,  1],\n",
      "        [39,  6, 26,  ..., 36,  1,  1],\n",
      "        [25,  2, 15,  ...,  3,  1,  1]]), tensor([46, 46, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
      "        45, 45, 45, 45, 45, 45, 45, 45, 44, 44, 44, 44, 44, 44]))\n",
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "32\n",
      "(tensor([[65, 10,  3,  ..., 35, 34, 54],\n",
      "        [39,  4, 20,  ...,  7, 18, 36],\n",
      "        [39,  3, 16,  ..., 36,  2,  1],\n",
      "        ...,\n",
      "        [69, 13,  2,  ..., 36,  2,  1],\n",
      "        [48,  8, 15,  ...,  5, 13,  1],\n",
      "        [39,  4, 20,  ..., 18, 13,  1]]), tensor([33, 33, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
      "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]))\n",
      "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "32\n",
      "(tensor([[55, 11,  3,  6,  9,  3,  2,  6,  9, 24,  2, 17, 14, 17, 17, 16,  2,  5,\n",
      "          4,  2, 19,  6, 11, 11,  2, 22,  6,  5, 12,  3, 10],\n",
      "        [32, 24,  2,  8,  2, 17,  9, 18,  2, 14,  2, 23, 51,  2,  8,  2, 11,  3,\n",
      "          6, 26,  3,  2, 17, 16,  2, 12,  4, 14,  9,  3, 13],\n",
      "        [41, 12,  6,  5,  2, 10,  2, 14,  2, 19,  4,  4, 24,  8,  7, 18,  2, 17,\n",
      "          3,  2, 22,  4, 10,  2, 15,  8,  7,  7,  3, 10, 36],\n",
      "        [30, 12,  6, 11, 11,  2, 19,  6, 11, 11,  2,  7,  4, 20,  2, 15,  3,  6,\n",
      "         10,  2, 12,  6, 26,  8,  7, 18,  2, 22,  4,  4, 15],\n",
      "        [30, 13,  8,  2,  5, 12,  8,  7, 24,  2, 12,  3,  2,  8,  9,  2, 20,  6,\n",
      "          9,  5,  3,  2, 22,  4, 10,  2, 10, 10, 13, 13,  1],\n",
      "        [39,  3, 16,  2, 19,  4, 17, 21,  6,  7, 16,  2,  3, 11,  6, 17,  6,  2,\n",
      "         21,  4,  2, 17, 14, 15, 16,  6, 15, 12, 14, 13,  1],\n",
      "        [25,  7,  2, 20, 12,  8, 19, 12,  2, 21, 11,  6, 19,  3,  2, 15,  4,  2,\n",
      "         16,  4, 14,  2, 20,  6,  7,  5,  2, 15,  6, 13,  1],\n",
      "        [34, 17,  2,  8,  7,  2, 22,  8, 11, 17,  2,  8, 11, 11,  2, 19,  6, 11,\n",
      "         11,  2, 16,  4, 14,  2, 11,  6,  5,  3, 10, 13,  1],\n",
      "        [54,  4, 11,  2, 16,  4, 14, 10,  2,  6, 11, 20,  6, 16,  9,  2,  9,  4,\n",
      "          2, 19,  4,  7, 26,  8,  7, 19,  8,  7, 18, 13,  1],\n",
      "        [37,  4,  2, 21, 10,  4, 23, 11,  3, 17, 13,  2, 39,  4, 20,  2,  6, 10,\n",
      "          3,  2, 16,  4, 14,  2, 15,  4,  8,  7, 18, 36,  1],\n",
      "        [25,  2, 41, 25, 54, 54,  2, 42, 34, 54,  2, 47, 32, 46,  2, 30, 25, 49,\n",
      "         13,  2, 25,  7,  2, 17,  3,  3,  5,  8,  7, 18,  1],\n",
      "        [25,  5, 85,  9,  2, 74, 59,  2,  5,  4,  2, 18,  3,  5,  2,  8,  7, 29,\n",
      "          2,  8,  9,  2,  5, 12,  6,  5,  2,  4, 24, 36,  1],\n",
      "        [42,  4, 10, 10,  3, 19,  5, 13,  2, 30,  4,  2, 12,  4, 20,  2, 20,  6,\n",
      "          9,  2, 20,  4, 10, 24,  2,  5,  4, 15,  6, 16,  1],\n",
      "        [48,  4,  2, 16,  4, 14,  2,  9,  5,  8, 11, 11,  2, 12,  6, 26,  3,  2,\n",
      "          5, 12,  3,  2, 18, 10,  8,  7, 15,  3, 10, 36,  1],\n",
      "        [34, 20,  3,  9,  4, 17,  3, 29,  2, 25, 31, 11, 11,  2,  9,  3,  3,  2,\n",
      "         16,  4, 14,  2,  8,  7,  2,  6,  2, 23,  8,  5,  1],\n",
      "        [55,  6, 19, 24,  6, 18,  3,  2,  6, 11, 11,  2, 16,  4, 14, 10,  2, 21,\n",
      "         10,  4, 18, 10,  6, 17,  9,  2, 20,  3, 11, 11,  1],\n",
      "        [39,  8,  2, 42, 12,  8, 24, 24, 14, 29,  2,  9,  3,  7, 15,  2,  9,  4,\n",
      "         17,  3,  2,  7,  8, 19,  3,  2, 17,  9, 18,  9,  1],\n",
      "        [47,  4, 14,  2, 15,  4,  7,  5,  2, 24,  7,  4, 20,  2, 16,  4, 14,  2,\n",
      "         62,  6, 23,  4,  2, 17,  3,  2,  6, 23,  8, 13,  1],\n",
      "        [25,  2,  6, 17,  2,  8,  7,  2,  5,  8, 10, 14, 21, 14, 10, 13,  2,  2,\n",
      "         19,  6, 11, 11,  2, 16,  4, 14,  2, 15,  6, 13,  1],\n",
      "        [25, 31, 17,  2,  8,  7,  2, 19, 11,  6,  9,  9, 13,  2, 41,  8, 11, 11,\n",
      "          2, 12,  4, 11, 11,  6,  2, 11,  6,  5,  3, 10,  1],\n",
      "        [48,  8,  9, 19, 14,  9,  9,  3, 15,  2, 20,  8,  5, 12,  2, 16,  4, 14,\n",
      "         10,  2, 17,  4,  5, 12,  3, 10,  2,  6, 12, 36,  1],\n",
      "        [39,  6, 26,  3,  2, 16,  4, 14,  2, 12,  3,  6, 10, 15,  2, 22, 10,  4,\n",
      "         17,  2,  5, 12,  8,  9,  2, 20,  3,  3, 24, 36,  1],\n",
      "        [47,  4,  2,  9,  4, 10, 10, 16,  2, 20,  6,  9,  2,  8,  7,  2,  5, 12,\n",
      "          3,  2,  9, 12,  4, 20,  3, 10,  2,  9, 14, 21,  1],\n",
      "        [47,  4, 14,  2,  8,  7,  2, 16,  4, 14, 10,  2, 10,  4,  4, 17, 36,  2,\n",
      "         25,  2,  7,  3,  3, 15,  2,  6,  2, 22,  3, 20,  1],\n",
      "        [37,  4, 13,  2, 47,  3,  9,  2, 21, 11,  3,  6,  9,  3, 13,  2, 56,  3,\n",
      "          3,  7,  2,  9, 20,  8, 17, 17,  8,  7, 18, 36,  1],\n",
      "        [35,  6, 10, 11, 16,  2, 23,  8, 10, 15, 40,  2, 34,  7, 16,  2, 21, 14,\n",
      "         10, 19, 12,  6,  9,  3,  9,  2, 16,  3,  5, 36,  1],\n",
      "        [41,  3, 31, 11, 11,  2, 62,  4,  8,  7,  2,  5, 12,  3,  2,  2, 52, 11,\n",
      "          5, 58, 71, 52, 18,  5, 58,  2,  2, 23, 14,  9,  1],\n",
      "        [28, 12,  6,  7, 24,  9, 29,  2, 25, 31, 11, 11,  2, 24,  3,  3, 21,  2,\n",
      "          5, 12,  6,  5,  2,  8,  7,  2, 17,  8,  7, 15,  1],\n",
      "        [25,  2,  6, 17,  2,  7,  4,  5,  2, 12,  6, 26,  8,  7, 18,  2, 12,  3,\n",
      "         10,  2,  7, 14, 17, 23,  3, 10,  2,  9,  8, 10,  1],\n",
      "        [30,  4,  2,  8, 31, 17,  2, 15,  4,  8,  7, 18,  2,  6,  2, 11,  8,  9,\n",
      "          5,  2,  4, 22,  2, 23, 14, 16,  3, 10,  9, 13,  1],\n",
      "        [48,  4,  7,  5,  2, 24,  7,  4, 20,  2, 16,  4, 14,  2, 23, 10,  8,  7,\n",
      "         18,  2,  9,  4, 17,  3,  2, 22,  4,  4, 15,  1,  1],\n",
      "        [30,  3,  3, 36,  2, 25,  2,  5, 12,  4, 14, 18, 12,  5,  2,  8,  5,  2,\n",
      "          6, 11, 11,  2,  5, 12, 10,  4, 14, 18, 12,  1,  1]]), tensor([31, 31, 31, 31, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 29, 29]))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "32\n",
      "(tensor([[34,  8, 16,  ..., 19, 24, 36],\n",
      "        [39,  3, 16,  ..., 15,  6, 13],\n",
      "        [48,  6, 10,  ...,  6, 10, 36],\n",
      "        ...,\n",
      "        [39,  8,  2,  ...,  5, 13,  1],\n",
      "        [41, 12,  6,  ..., 15, 36,  1],\n",
      "        [47,  4, 14,  ..., 57, 60,  1]]), tensor([48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47,\n",
      "        47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47]))\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1])\n",
      "32\n",
      "(tensor([[65, 10,  3,  ...,  3,  7, 15],\n",
      "        [49,  3, 21,  ..., 44, 27, 21],\n",
      "        [65,  8,  7,  ...,  2, 33, 59],\n",
      "        ...,\n",
      "        [46, 10, 18,  ..., 60, 34, 73],\n",
      "        [46, 10, 18,  ..., 57, 47, 65],\n",
      "        [55, 11,  3,  ..., 15, 16, 13]]), tensor([159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159, 159,\n",
      "        159, 159, 159, 159]))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0])\n",
      "32\n",
      "(tensor([[55, 10,  4,  ...,  9, 14, 23],\n",
      "        [55, 10,  4,  ...,  9, 14, 23],\n",
      "        [55, 10,  4,  ...,  9, 14, 23],\n",
      "        ...,\n",
      "        [78, 33, 38,  ...,  1,  1,  1],\n",
      "        [78, 33, 38,  ...,  1,  1,  1],\n",
      "        [28, 12,  6,  ...,  1,  1,  1]]), tensor([177, 177, 177, 175, 175, 175, 175, 175, 174, 174, 173, 173, 172, 172,\n",
      "        172, 172, 172, 172, 172, 172, 172, 172, 172, 172, 170, 169, 169, 169,\n",
      "        169, 169, 169, 168]))\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0])\n",
      "32\n",
      "(tensor([[41,  8, 11,  ...,  6, 11, 13],\n",
      "        [37,  4,  2,  ...,  4, 20, 13],\n",
      "        [34, 17, 23,  ..., 23, 10, 36],\n",
      "        ...,\n",
      "        [25,  7, 15,  ...,  2, 40,  1],\n",
      "        [30, 14, 10,  ..., 20, 13,  1],\n",
      "        [34,  8, 18,  ..., 36,  1,  1]]), tensor([52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 51, 51, 51, 51, 51,\n",
      "        51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 50]))\n",
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "32\n",
      "(tensor([[37,  4,  2,  ..., 17,  3, 13],\n",
      "        [ 2,  9,  6,  ..., 16, 40,  2],\n",
      "        [28, 12,  3,  ...,  4, 13, 76],\n",
      "        ...,\n",
      "        [41, 25, 37,  ..., 14, 24,  1],\n",
      "        [46,  2, 12,  ..., 59, 44,  1],\n",
      "        [46,  2, 12,  ..., 59, 44,  1]]), tensor([133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
      "        133, 133, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132, 132,\n",
      "        132, 132, 132, 132]))\n",
      "tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for batch in train_iter:\n",
    "    x = x + 1\n",
    "    print(len(batch))\n",
    "    print(batch.sms) \n",
    "    print(batch.label)\n",
    "    if x == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "import torch\n",
    "ident = torch.eye(50)\n",
    "print(ident[0]) \n",
    "print(ident[1]) \n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "print(ident[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SpamRNN, self).__init__()\n",
    "        self.ident = torch.eye(input_size)\n",
    "        print(torch.eye(input_size))\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "\n",
    "        print(inp)\n",
    "        inp = self.ident[inp]\n",
    "        h0 = torch.zeros(1, inp.size(0), self.hidden_size)\n",
    "        out, _ = self.rnn(inp)\n",
    "        out = torch.cat([torch.max(out, dim=1)[0], torch.mean(out, dim=1)], dim=1)\n",
    "        self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a\n",
    "\n",
    "trainIter = torchtext.data.BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.sms), sort_within_batch=True, repeat=False)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(model, data):\n",
    "    \n",
    "    correct, total = 0, 0\n",
    "    for sms, labels in data:\n",
    "        output = model(sms)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += labels.shape[0]\n",
    "        \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
    "valLoader = torch.utils.data.DataLoader(valid, batch_size=16, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_network(model, train, valid, numEpochs=5, learningRate=1e-5):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "    losses, trainAcc, valAcc = [], [], []\n",
    "    epochs = []\n",
    "    for epoch in range(numEpochs):\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        for sms, labels in train:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(sms)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(float(loss))\n",
    "\n",
    "        epochs.append(epoch)\n",
    "        trainAcc.append(get_accuracy(model, trainLoader))\n",
    "        valAcc.append(get_accuracy(model, valLoader))\n",
    "        print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (epoch+1, loss, traiAcc[-1], valAcc[-1]))\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(losses, label=\"Train\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epochs, train_acc, label=\"Train\")\n",
    "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torchtext.data.example.Example'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-061d828a177b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mspam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpamRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_rnn_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumEpochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-09b8010319cf>\u001b[0m in \u001b[0;36mtrain_rnn_network\u001b[1;34m(model, train, valid, numEpochs, learningRate)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torchtext.data.example.Example'>"
     ]
    }
   ],
   "source": [
    "spam = SpamRNN(50, 50, 2)\n",
    "train_rnn_network(spam, trainLoader, valLoader, numEpochs=5, learningRate=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3c\n",
    "\n",
    "\"\"\"\n",
    "I will choose learning rate, epoch, batch size and hidden size\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = SpamRNN(50, 50, 2)\n",
    "train_rnn_network(spam, trainLoader, valLoader, numEpochs=5, learningRate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = SpamRNN(50, 50, 2)\n",
    "train_rnn_network(spam, trainLoader, valLoader, numEpochs=5, learningRate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = SpamRNN(50, 50, 2)\n",
    "train_rnn_network(spam, trainLoader, valLoader, numEpochs=30, learningRate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = SpamRNN(50, 50, 2)\n",
    "train_rnn_network(spam, trainLoader, valLoader, numEpochs=30, batch_size=64, learningRate=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
